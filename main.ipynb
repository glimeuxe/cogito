{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import os for operating system functions.\n",
    "import os\n",
    "# Import numpy for mathematical computation.\n",
    "import numpy as np\n",
    "# Import pandas for data manipulation.\n",
    "import pandas as pd\n",
    "# Import datetime for local time retrieval.\n",
    "from datetime import datetime\n",
    "# Import logging for file logging.\n",
    "import logging\n",
    "# Import time for duration measurement.\n",
    "import time\n",
    "\n",
    "# Import random, clone, make_scorer, and _fit_and_score for simulated annealing.\n",
    "import random\n",
    "from sklearn.base import clone\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection._validation import _fit_and_score\n",
    "\n",
    "# Import StandardScaler for data pre-processing.\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# Import train_test_split for model selection.\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Import KFold and f1_score for cross-validation.\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "\n",
    "# Import SK, XGB, and CatBoost classifiers.\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, HistGradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "\tfilename=\"main.log\",\n",
    "\tlevel=logging.INFO,\n",
    "\tformat=\"%(asctime)s - %(message)s\",\n",
    "\tdatefmt=\"%Y-%m-%d %H:%M:%S\"\n",
    ")\n",
    "\n",
    "HYPERPARAMETER_ALIASES = {\n",
    "\t\"α\": \"learning_rate\",\n",
    "\t\"τ\": \"max_iter\",\n",
    "\t\"θ\": \"max_leaf_nodes\",\n",
    "\t\"Δ\": \"max_depth\",\n",
    "\t\"l\": \"min_samples_leaf\",\n",
    "\t\"seed\": \"random_state\"\n",
    "}\n",
    "\n",
    "MODEL_CLASSES = {\n",
    "\t\"SKLknn\": KNeighborsClassifier,\n",
    "\t\"SKLsvm\": SVC,\n",
    "\t\"SKLrf\": RandomForestClassifier,\n",
    "\t\"SKLgb\": GradientBoostingClassifier,\n",
    "\t\"SKLhgb\": HistGradientBoostingClassifier,\n",
    "\t\"XGBgb\": XGBClassifier,\n",
    "\t\"CBgb\": CatBoostClassifier\n",
    "}\n",
    "\n",
    "# Load train and test datasets.\n",
    "S_train = pd.read_csv(\"./data/train.csv\")\n",
    "S_train_tfidf = pd.read_csv(\"./data/train_tfidf_features.csv\")\n",
    "S_test = pd.read_csv(\"./data/test.csv\")\n",
    "S_test_tfidf = pd.read_csv(\"./data/test_tfidf_features.csv\")\n",
    "\n",
    "# Extract train features, train labels, and test features.\n",
    "X_train = S_train_tfidf.iloc[:, 2:].values\n",
    "y_train = S_train[\"label\"].values.reshape(-1, 1)\n",
    "X_test = S_test_tfidf.iloc[:, 1:].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### logreg Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def σ(z): return 1 / (1 + np.exp(-z))\n",
    "def bce_loss(y, ŷ): return (-1/(y.shape[0])) * np.sum(y * np.log(ŷ) + (1 - y) * np.log(1 - ŷ))\n",
    "\n",
    "# Return dw and db, for some X, y, ŷ, w, R, and λ.\n",
    "def gradients_logreg(X, y, ŷ, w, R=None, λ=0):\n",
    "\tm, _ = X.shape\n",
    "\tdw = 1/m * np.dot(X.T, (ŷ - y))\n",
    "\tdb = 1/m * np.sum(ŷ - y)\n",
    "\tif R == \"L2\":\n",
    "\t\tdw += λ * w / m\n",
    "\telif R == \"L1\":\n",
    "\t\tdw += λ * np.sign(w) / m\n",
    "\treturn dw, db\n",
    "\n",
    "# Return (w, b) from gradient descent on X_train and y_train, for some τ, α, G, β, R, and λ.\n",
    "def train_logreg(X_train, y_train, τ=1000, α=0.1, G=\"mini-batch\", β=128, R=None, λ=0):\n",
    "\tm, n = X_train.shape\n",
    "\tw, b = np.zeros((n, 1)), 0\n",
    "\tfor epoch in range(τ):\n",
    "\t\tif G == \"full-batch\":\n",
    "\t\t\tX_batch, y_batch = X_train, y_train\n",
    "\t\t\tŷ = σ(np.dot(X_batch, w) + b)\n",
    "\t\t\tdw, db = gradients_logreg(X_batch, y_batch, ŷ, w, R, λ)\n",
    "\t\t\tw, b = w - α*dw, b - α*db\n",
    "\t\telif G == \"mini-batch\":\n",
    "\t\t\tfor i in range(0, m, β):\n",
    "\t\t\t\tX_batch, y_batch = X_train[i:i+β], y_train[i:i+β]\n",
    "\t\t\t\tŷ = σ(np.dot(X_batch, w) + b)\n",
    "\t\t\t\tdw, db = gradients_logreg(X_batch, y_batch, ŷ, w, R, λ)\n",
    "\t\t\t\tw, b = w - α*dw, b - α*db\n",
    "\t\telif G == \"stochastic\":\n",
    "\t\t\tfor i in range(m):\n",
    "\t\t\t\tX_batch, y_batch = X_train[i:i+1], y_train[i:i+1]\n",
    "\t\t\t\tŷ = σ(np.dot(X_batch, w) + b)\n",
    "\t\t\t\tdw, db = gradients_logreg(X_batch, y_batch, ŷ, w, R, λ)\n",
    "\t\t\t\tw, b = w - α*dw, b - α*db\n",
    "\treturn w, b\n",
    "\n",
    "# Return array of predictions, where each prediction is 1 if corresponding ŷ entry > 0.5, and 0 otherwise.\n",
    "def predict_logreg(wb_tuple, X):\n",
    "\tw, b = wb_tuple\n",
    "\tŷ = σ(np.dot(X, w) + b)\n",
    "\treturn np.array([1 if p > 0.5 else 0 for p in ŷ])\n",
    "\n",
    "# Train model, make predictions, and save predictions to CSV file.\n",
    "def generate_predictions_logreg(τ=1000, α=0.1, G=\"mini-batch\", β=128, R=None, λ=0):\n",
    "\tstart_time = time.time()\n",
    "\tw, b = train_logreg(np.array(X_train), np.array(y_train), τ, α, G, β, R, λ)\n",
    "\tpredictions = predict_logreg((w, b), np.array(X_test))\n",
    "\tos.makedirs(\"./predictions/logreg/\", exist_ok=True)\n",
    "\tfile_name = os.path.join(\"./predictions/logreg/\", f\"τ={τ},α={α},G={G},β={β},R={R},λ={λ}.csv\")\n",
    "\tpd.DataFrame({\"id\": S_test[\"id\"], \"label\": predictions}).to_csv(file_name, index=False)\n",
    "\tend_time = time.time()\n",
    "\tlogging.info(f\"Predictions file {file_name} generated in {end_time - start_time:.2f}s.\")\n",
    "\tprint(f\"Predictions file {file_name} generated in {end_time - start_time:.2f}s.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_pca(x):\n",
    "\tscaler = StandardScaler()\n",
    "\tX_train_scaled = scaler.fit_transform(X_train)\n",
    "\tX_test_scaled = scaler.transform(X_test)\n",
    "\tif 0 <= x <= 1:\n",
    "\t\t# x represents variance threshold.\n",
    "\t\tpca = PCA(n_components=None)\n",
    "\t\tpca.fit(X_train_scaled)\n",
    "\t\tc = np.argmax(np.cumsum(pca.explained_variance_ratio_) >= x) + 1\n",
    "\t\tv = x\n",
    "\telse:\n",
    "\t\t# x represents number of components.\n",
    "\t\tpca = PCA(n_components=x)\n",
    "\t\tpca.fit(X_train_scaled)\n",
    "\t\tc = x\n",
    "\t\tv = sum(pca.explained_variance_ratio_)\n",
    "\t# Transform train and test datasets.\n",
    "\tX_train_pca = pca.transform(X_train_scaled)\n",
    "\tX_test_pca = pca.transform(X_test_scaled)\n",
    "\treturn X_train_pca, X_test_pca, c, v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SKLknn Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_SKLknn(X_train, y_train, k=5, W=\"uniform\", p=2, m=\"minkowski\"):\n",
    "\tmodel = KNeighborsClassifier(\n",
    "\t\tn_neighbors=k,\n",
    "\t\tweights=W,\n",
    "\t\tp=p,\n",
    "\t\tmetric=m,\n",
    "\t\tn_jobs=-1\n",
    "\t)\n",
    "\tmodel.fit(X_train, y_train)\n",
    "\treturn model\n",
    "\n",
    "def predict_SKLknn(model, X): return model.predict(X)\n",
    "\n",
    "def generate_predictions_SKLknn(k=5, W=\"uniform\", p=2, m=\"minkowski\"):\n",
    "\tstart_time = time.time()\n",
    "\tmodel = train_SKLknn(np.array(X_train), np.array(y_train), k, W, p, m)\n",
    "\tpredictions = predict_SKLknn(model, np.array(X_test))\n",
    "\tos.makedirs(\"./predictions/SKLknn/\", exist_ok=True)\n",
    "\tfile_name = os.path.join(\"./predictions/SKLknn/\", f\"k={k},W={W},p={p},m={m}.csv\")\n",
    "\tpd.DataFrame({\"id\": S_test[\"id\"], \"label\": predictions}).to_csv(file_name, index=False)\n",
    "\tend_time = time.time()\n",
    "\tlogging.info(f\"Predictions file {file_name} generated in {end_time - start_time:.2f}s.\")\n",
    "\tprint(f\"Predictions file {file_name} generated in {end_time - start_time:.2f}s.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model, make model predictions, and save model predictions to CSV file.\n",
    "def generate_predictions_pcaknn(x):\n",
    "\tstart_time = time.time()\n",
    "\tX_train_pca, X_test_pca, c, v = apply_pca(x)\n",
    "\tmodel = train_SKLknn(X_train_pca, y_train, k=2)\n",
    "\tpredictions = predict_SKLknn(model, X_test_pca)\n",
    "\tos.makedirs(\"./predictions/pcaknn/\", exist_ok=True)\n",
    "\tfile_name = os.path.join(\"./predictions/pcaknn/\", f\"pcaknn(ρ={c},ν={v:.2f}).csv\")\n",
    "\tpd.DataFrame({\"id\": S_test[\"id\"], \"label\": predictions}).to_csv(file_name, index=False)\n",
    "\tend_time = time.time()\n",
    "\tlogging.info(f\"Predictions file {file_name} generated in {end_time - start_time:.2f}s.\")\n",
    "\tprint(f\"Predictions file {file_name} generated in {end_time - start_time:.2f}s.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Other Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SKLlogreg Model (WIP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SKLrf Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_SKLrf(X_train, y_train, η=100, cri=\"gini\", Δ=None, ψ=2, l=1, θ=None, seed=None):\n",
    "\tmodel = RandomForestClassifier(\n",
    "\t\tn_estimators=η,\n",
    "\t\tcriterion=cri,\n",
    "\t\tmax_depth=Δ,\n",
    "\t\tmin_samples_split=ψ,\n",
    "\t\tmin_samples_leaf=l,\n",
    "\t\tmax_leaf_nodes=θ,\n",
    "\t\tn_jobs=-1,\n",
    "\t\trandom_state=seed\n",
    "\t)\n",
    "\tmodel.fit(X_train, y_train.ravel())\n",
    "\treturn model\n",
    "\n",
    "def predict_SKLrf(model, X): return model.predict(X)\n",
    "\n",
    "def generate_predictions_SKLrf(η=100, cri=\"gini\", Δ=None, ψ=2, l=1, θ=None, seed=None):\n",
    "\tstart_time = time.time()\n",
    "\tmodel = train_SKLrf(np.array(X_train), np.array(y_train), η, cri, Δ, ψ, l, θ, seed)\n",
    "\tpredictions = predict_SKLrf(model, np.array(X_test))\n",
    "\tos.makedirs(\"./predictions/SKLrf/\", exist_ok=True)\n",
    "\tfile_name = os.path.join(\"./predictions/SKLrf/\", f\"η={η},cri={cri},Δ={Δ},ψ={ψ},l={l},θ={θ},seed={seed}.csv\")\n",
    "\tpd.DataFrame({\"id\": S_test[\"id\"], \"label\": predictions}).to_csv(file_name, index=False)\n",
    "\tend_time = time.time()\n",
    "\tlogging.info(f\"Predictions file {file_name} generated in {end_time - start_time:.2f}s.\")\n",
    "\tprint(f\"Predictions file {file_name} generated in {end_time - start_time:.2f}s.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SKLsvm Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model, make predictions, and save predictions to CSV file.\n",
    "def train_SKLsvm(X_train, y_train, C=1.0, ker=\"rbf\", d=3, γ=\"scale\", τ=-1, seed=None):\n",
    "\tmodel = SVC(\n",
    "\t\tC=C,\n",
    "\t\tkernel=ker,\n",
    "\t\tdegree=d,\n",
    "\t\tgamma=γ,\n",
    "\t\tmax_iter=τ,\n",
    "\t\trandom_state=seed\n",
    "\t)\n",
    "\tmodel.fit(X_train, y_train.ravel())\n",
    "\treturn model\n",
    "\n",
    "def predict_SKLsvm(model, X): return model.predict(X)\n",
    "\n",
    "def generate_predictions_SKLsvm(C=1.0, ker=\"rbf\", d=3, γ=\"scale\", τ=-1, seed=None):\n",
    "\tstart_time = time.time()\n",
    "\tmodel = train_SKLsvm(np.array(X_train), np.array(y_train), C, ker, d, γ, τ, seed)\n",
    "\tpredictions = predict_SKLsvm(model, np.array(X_test))\n",
    "\tos.makedirs(\"./predictions/SKLsvm/\", exist_ok=True)\n",
    "\tfile_name = os.path.join(\"./predictions/SKLsvm/\", f\"C={C},ker={K},d={d},γ={γ},τ={τ},seed={seed}.csv\")\n",
    "\tpd.DataFrame({\"id\": S_test[\"id\"], \"label\": predictions}).to_csv(file_name, index=False)\n",
    "\tend_time = time.time()\n",
    "\tlogging.info(f\"Predictions file {file_name} generated in {end_time - start_time:.2f}s.\")\n",
    "\tprint(f\"Predictions file {file_name} generated in {end_time - start_time:.2f}s.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SKLgb Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_SKLgb(X_train, y_train, α=0.1, η=100, ss=1.0, ψ=2, l=1, Δ=3, seed=None, θ=None):\n",
    "\tmodel = GradientBoostingClassifier(\n",
    "\t\tlearning_rate=α,\n",
    "\t\tn_estimators=η,\n",
    "\t\tsubsample=ss,\n",
    "\t\tmin_samples_split=ψ,\n",
    "\t\tmin_samples_leaf=l,\n",
    "\t\tmax_depth=Δ,\n",
    "\t\trandom_state=seed,\n",
    "\t\tmax_leaf_nodes=θ\n",
    "\t)\n",
    "\tmodel.fit(X_train, y_train)\n",
    "\treturn model\n",
    "\n",
    "def predict_SKLgb(model, X): return model.predict(X)\n",
    "\n",
    "def generate_predictions_SKLgb(α=0.1, η=100, ss=1.0, ψ=2, l=1, Δ=3, seed=None, θ=None):\n",
    "\tstart_time = time.time()\n",
    "\tmodel = train_SKLgb(np.array(X_train), np.array(y_train), α, η, ss, ψ, l, Δ, seed, θ)\n",
    "\tpredictions = predict_SKLgb(model, np.array(X_test))\n",
    "\tos.makedirs(\"./predictions/SKLgb/\", exist_ok=True)\n",
    "\tfile_name = os.path.join(\"./predictions/SKLgb/\", f\"α={α},η={η},ss={ss},ψ={ψ},l={l},Δ={Δ},seed={seed},θ={θ}.csv\")\n",
    "\tpd.DataFrame({\"id\": S_test[\"id\"], \"label\": predictions}).to_csv(file_name, index=False)\n",
    "\tend_time = time.time()\n",
    "\tlogging.info(f\"Predictions file {file_name} generated in {end_time - start_time:.2f}s.\")\n",
    "\tprint(f\"Predictions file {file_name} generated in {end_time - start_time:.2f}s.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SKLhgb Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_SKLhgb(X_train, y_train, α=0.1, τ=100, θ=31, Δ=None, l=20, seed=None):\n",
    "\tmodel = HistGradientBoostingClassifier(\n",
    "\t\tlearning_rate=α,\n",
    "\t\tmax_iter=τ,\n",
    "\t\tmax_leaf_nodes=θ,\n",
    "\t\tmax_depth=Δ,\n",
    "\t\tmin_samples_leaf=l,\n",
    "\t\trandom_state=seed\n",
    "\t)\n",
    "\tmodel.fit(X_train, y_train)\n",
    "\treturn model\n",
    "\n",
    "def predict_SKLhgb(model, X): return model.predict(X)\n",
    "\n",
    "def generate_predictions_SKLhgb(α=0.1, τ=100, θ=31, Δ=None, l=20, seed=None):\n",
    "\tstart_time = time.time()\n",
    "\tmodel = train_SKLhgb(np.array(X_train), np.array(y_train), α, τ, θ, Δ, l, seed)\n",
    "\tpredictions = predict_SKLhgb(model, np.array(X_test))\n",
    "\tos.makedirs(\"./predictions/SKLhgb/\", exist_ok=True)\n",
    "\tfile_name = os.path.join(\"./predictions/SKLhgb/\", f\"α={α},τ={τ},θ={θ},Δ={Δ},l={l},seed={seed}.csv\")\n",
    "\tsubmission = pd.DataFrame({\"id\": S_test[\"id\"], \"label\": predictions}).to_csv(file_name, index=False)\n",
    "\tend_time = time.time()\n",
    "\tlogging.info(f\"Predictions file {file_name} generated in {end_time - start_time:.2f}s.\")\n",
    "\tprint(f\"Predictions file {file_name} generated in {end_time - start_time:.2f}s.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBgb Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_XGBgb(X_train, y_train, η=100, Δ=3, Θ=0, α=0.1, B=\"gbtree\", ss=1, l1=0, l2=1, seed=None):\n",
    "\txgb_model = XGBClassifier(\n",
    "\t\tn_estimators=η,\n",
    "\t\tmax_depth=Δ,\n",
    "\t\tmax_leaves=Θ if Θ > 0 else None,\n",
    "\t\tlearning_rate=α,\n",
    "\t\tobjective=\"binary:logistic\",\n",
    "\t\tbooster=B,\n",
    "\t\tsubsample=ss,\n",
    "\t\treg_alpha=l1,\n",
    "\t\treg_lambda=l2,\n",
    "\t\trandom_state=seed,\n",
    "\t\tn_jobs=-1\n",
    "\t)\n",
    "\txgb_model.fit(X_train, y_train.ravel())\n",
    "\treturn xgb_model\n",
    "\n",
    "def predict_XGBgb(model, X):\n",
    "\treturn model.predict(X)\n",
    "\n",
    "def generate_predictions_XGBgb(η=100, Δ=3, Θ=0, α=0.1, B=\"gbtree\", ss=1, l1=0, l2=1, seed=None):\n",
    "\tstart_time = time.time()\n",
    "\txgb_model = train_XGBgb(np.array(X_train), np.array(y_train), η, Δ, Θ, α, B, ss, l1, l2, seed)\n",
    "\tpredictions = predict_XGBgb(xgb_model, np.array(X_test))\n",
    "\tos.makedirs(\"./predictions/XGBgb/\", exist_ok=True)\n",
    "\tfile_name = os.path.join(\"./predictions/XGBgb/\", f\"η={η},Δ={Δ},Θ={Θ},α={α},B={B},ss={ss},l1={l1},l2={l2},seed={seed}.csv\")\n",
    "\tpd.DataFrame({\"id\": S_test[\"id\"], \"label\": predictions}).to_csv(file_name, index=False)\n",
    "\tend_time = time.time()\n",
    "\tlogging.info(f\"Predictions file {file_name} generated in {end_time - start_time:.2f}s.\")\n",
    "\tprint(f\"Predictions file {file_name} generated in {end_time - start_time:.2f}s.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CBgb Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_CBgb(X_train, y_train, t=None, α=None, δ=None, l2l=None, ss=None, Δ=None, η=None, l2=None, seed=None):\n",
    "\tmodel = CatBoostClassifier(\n",
    "\t\titerations=t,\n",
    "\t\tlearning_rate=α,\n",
    "\t\tdepth=δ,\n",
    "\t\tl2_leaf_reg=l2l,\n",
    "\t\tsubsample=ss,\n",
    "\t\tmax_depth=Δ,\n",
    "\t\tn_estimators=η,\n",
    "\t\treg_lambda=l2,\n",
    "\t\trandom_state=seed\n",
    "\t)\n",
    "\tmodel.fit(X_train, y_train)\n",
    "\treturn model\n",
    "\n",
    "def predict_CBgb(model, X): return model.predict(X)\n",
    "\n",
    "def generate_predictions_CBgb(t=None, α=None, δ=None, l2l=None, ss=None, Δ=None, η=None, l2=None, seed=None):\n",
    "\tstart_time = time.time()\n",
    "\tmodel = train_CBgb(np.array(X_train), np.array(y_train), t, α, δ, l2l, ss, Δ, η, l2, seed)\n",
    "\tpredictions = predict_CBgb(model, np.array(X_test))\n",
    "\tos.makedirs(\"./predictions/CBgb/\", exist_ok=True)\n",
    "\tfile_name = os.path.join(\"./predictions/CBgb/\", f\"t={t},α={α},δ={δ},l2l={l2l},ss={ss},Δ={Δ},η={η},l2={l2},seed={seed}.csv\")\n",
    "\tpd.DataFrame({\"id\": S_test[\"id\"], \"label\": predictions}).to_csv(file_name, index=False)\n",
    "\tend_time = time.time()\n",
    "\tlogging.info(f\"Predictions file {file_name} generated in {end_time - start_time:.2f}s.\")\n",
    "\tprint(f\"Predictions file {file_name} generated in {end_time - start_time:.2f}s.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-Validation Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossvalidate_grid(train_fn, predict_fn, grid, X, y, k=2):\n",
    "\tkf = KFold(n_splits=k, shuffle=True)\n",
    "\tbest_f1 = -np.inf\n",
    "\tbest_hyperparameters = None\n",
    "\tfor hyperparameters in grid:\n",
    "\t\tf1_scores = []\n",
    "\t\tfor i_train, i_val in kf.split(X):\n",
    "\t\t\tX_train, X_val = X[i_train], X[i_val]\n",
    "\t\t\ty_train, y_val = y[i_train], y[i_val]\n",
    "\t\t\tmodel = train_fn(X_train, y_train, **hyperparameters)\n",
    "\t\t\ty_pred = predict_fn(model, X_val)\n",
    "\t\t\tf1_scores.append(f1_score(y_val, y_pred, average=\"macro\"))\n",
    "\t\tmean_f1 = np.mean(f1_scores)\n",
    "\t\tif mean_f1 > best_f1:\n",
    "\t\t\tbest_f1 = mean_f1\n",
    "\t\t\tbest_hyperparameters = hyperparameters\n",
    "\tprint(f\"Best hyperparameters in grid:\", best_hyperparameters)\n",
    "\tprint(f\"Best {k}-fold cross-validation f1 score:\", best_f1)\n",
    "\treturn best_hyperparameters, best_f1\n",
    "\n",
    "# def crossvalidate_and_generate_predictions_grid(model_name, grid, k=5):\n",
    "# \ttrain_fn = globals().get(f\"train_{model_name.lower()}\")\n",
    "# \tpredict_fn = globals().get(f\"predict_{model_name.lower()}\")\n",
    "# \tgenerate_predictions_fn = globals().get(f\"generate_predictions_{model_name.lower()}\")\n",
    "# \tif not train_fn or not predict_fn or not generate_predictions_fn: raise ValueError(f\"Expected train_{model_name} or predict_{model_name} to exist.\")\n",
    "# \tbest_hyperparameters, _ = crossvalidate_grid(train_fn, predict_fn, grid, X_train, y_train, k=k)\n",
    "# \tgenerate_predictions_fn(**best_hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid = [\n",
    "# \t{\"τ\": 10000, \"α\": 0.0825, \"G\": \"mini-batch\", \"β\": 128, \"R\": \"L2\", \"λ\": 1},\n",
    "# \t{\"τ\": 10000, \"α\": 0.085, \"G\": \"mini-batch\", \"β\": 128, \"R\": \"L2\", \"λ\": 1}\n",
    "# ]\n",
    "# crossvalidate_and_generate_predictions(\"logreg\", grid, k=2)\n",
    "\n",
    "# grid = [\n",
    "# \t{\"η\": 100, \"C\": \"gini\", \"Δ\": None, \"ψ\": 2, \"l\": 1, \"θ\": None, \"seed\": None},\n",
    "# \t{\"η\": 200, \"C\": \"entropy\", \"Δ\": 10, \"ψ\": 3, \"l\": 2, \"θ\": 50, \"seed\": 42}\n",
    "# ]\n",
    "# crossvalidate_and_generate_predictions(\"SKLrf\", grid, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SA:\n",
    "\tdef __init__(self, estimator, grid, scoring=f1_score, T=10, T_min=0.001, α=0.9, n_trans=5, max_iter=100, max_runtime=60, cv=5, n_jobs=-1, max_f1=np.inf, min_improvement=1e-4, patience=10):\n",
    "\t\tself.estimator = estimator\n",
    "\t\tself.grid = grid\n",
    "\t\tself.scoring = scoring\n",
    "\t\tself.T = T\n",
    "\t\tself.T_min = T_min\n",
    "\t\tself.α = α\n",
    "\t\tself.n_trans = n_trans\n",
    "\t\tself.max_iter = max_iter\n",
    "\t\tself.max_runtime = max_runtime\n",
    "\t\tself.cv = cv\n",
    "\t\tself.n_jobs = n_jobs\n",
    "\t\tself.max_f1 = max_f1\n",
    "\t\tself.min_improvement = min_improvement\n",
    "\t\tself.patience = patience\n",
    "\n",
    "\t\tself.best_hyperparameters_ = None\n",
    "\t\tself.best_f1_ = None\n",
    "\t\tself.grid_f1s_ = None\n",
    "\t\tself.runtime_ = None\n",
    "\t\tself._set_dynamic_params()\n",
    "\n",
    "\tdef _set_dynamic_params(self):\n",
    "\t\tnum_hyperparameters = np.prod([len(v) for v in self.grid.values() if isinstance(v, list)])\n",
    "\t\tself.T = 10 * num_hyperparameters\n",
    "\t\tself.T_min = 0.01 * self.T\n",
    "\t\tself.α = 0.9\n",
    "\n",
    "\tdef _accept_prob(self, old_f1, new_f1, T):\n",
    "\t\tT += 0.01\n",
    "\t\treturn np.exp((new_f1 - old_f1) / T)\n",
    "\n",
    "\tdef _dt(self, t0, t1): return t1 - t0 if t0 is not None else 0\n",
    "\n",
    "\tdef fit(self, X, y):\n",
    "\t\tif isinstance(X, pd.DataFrame):\n",
    "\t\t\tX = X.to_numpy()\n",
    "\t\tif isinstance(y, pd.DataFrame):\n",
    "\t\t\ty = y.to_numpy()\n",
    "\t\telif isinstance(y, (list, pd.Series)):\n",
    "\t\t\ty = np.array(y)\n",
    "\t\tT = self.T\n",
    "\t\tT_min = self.T_min\n",
    "\t\tα = self.α\n",
    "\t\tmax_iter = self.max_iter\n",
    "\t\tn_trans = self.n_trans\n",
    "\t\tgrid = self.grid\n",
    "\t\tmax_runtime = self.max_runtime\n",
    "\t\tcv = self.cv\n",
    "\t\told_hyperparameters = {k: np.random.choice(v) if isinstance(v, list) else np.random.uniform(v[0], v[1]) for k, v in grid.items()}\n",
    "\t\told_est = clone(self.estimator)\n",
    "\t\told_est.set_params(**old_hyperparameters)\n",
    "\t\told_f1, old_std = self._evaluate_f1(old_est, X, y, cv)\n",
    "\t\tbest_f1 = old_f1\n",
    "\t\tbest_hyperparameters = old_hyperparameters\n",
    "\t\tstates_checked = {tuple(sorted(old_hyperparameters.items())): (old_f1, old_std)}\n",
    "\t\ttotal_iter = 1\n",
    "\t\tgrid_f1s = [(1, T, old_f1, old_std, old_hyperparameters)]\n",
    "\t\ttime_at_start = time.time()\n",
    "\t\tt_elapsed = self._dt(time_at_start, time.time())\n",
    "\t\tno_improvement_count = 0\n",
    "\t\twhile T > T_min and total_iter < max_iter and t_elapsed < max_runtime and best_f1 < self.max_f1:\n",
    "\t\t\tfor _ in range(self.n_trans):\n",
    "\t\t\t\tnew_hyperparameters = self._generate_new_hyperparameters(old_hyperparameters, grid)\n",
    "\t\t\t\tnew_f1, new_std = self._evaluate_f1_for_hyperparameters(new_hyperparameters, X, y, cv, states_checked)\n",
    "\t\t\t\tif new_f1 >= self.max_f1: break\n",
    "\t\t\t\tgrid_f1s.append((total_iter, T, new_f1, new_std, new_hyperparameters))\n",
    "\t\t\t\tif new_f1 > best_f1:\n",
    "\t\t\t\t\tbest_f1 = new_f1\n",
    "\t\t\t\t\tbest_hyperparameters = new_hyperparameters\n",
    "\t\t\t\t\tno_improvement_count = 0\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tno_improvement_count += 1\n",
    "\t\t\t\tprint(f\"{total_iter} T: {T:.5f}, f1: {new_f1:.6f}, std: {new_std:.6f}, hyperparameters: {new_hyperparameters}\")\n",
    "\t\t\t\tif self._accept_prob(old_f1, new_f1, T) > np.random.random():\n",
    "\t\t\t\t\told_hyperparameters = new_hyperparameters\n",
    "\t\t\t\t\told_f1 = new_f1\n",
    "\t\t\t\tt_elapsed = self._dt(time_at_start, time.time())\n",
    "\t\t\t\ttotal_iter += 1\n",
    "\t\t\tif new_f1 >= self.max_f1:\n",
    "\t\t\t\tprint(f\"Max f1 reached {new_f1}!\")\n",
    "\t\t\t\tbreak\n",
    "\t\t\tif no_improvement_count >= self.patience and T <= self.T_min:\n",
    "\t\t\t\tprint(\"Early stopping due to lack of improvement.\")\n",
    "\t\t\t\tbreak\n",
    "\t\t\tT *= α\n",
    "\t\tself.runtime_ = t_elapsed\n",
    "\t\tself.grid_f1s_ = grid_f1s\n",
    "\t\tself.best_f1_ = best_f1\n",
    "\t\tself.best_hyperparameters_ = best_hyperparameters\n",
    "\n",
    "\tdef _generate_new_hyperparameters(self, old_hyperparameters, grid):\n",
    "\t\tnew_hyperparameters = old_hyperparameters.copy()\n",
    "\t\trand_key = np.random.choice(list(grid.keys()))\n",
    "\t\tval = grid[rand_key]\n",
    "\t\tif isinstance(val, list):\n",
    "\t\t\tsample_space = [v for v in val if v != old_hyperparameters[rand_key]]\n",
    "\t\t\tnew_hyperparameters[rand_key] = np.random.choice(sample_space) if sample_space else np.random.choice(val)\n",
    "\t\telif isinstance(val, tuple) and len(val) == 2:\n",
    "\t\t\tnew_hyperparameters[rand_key] = np.random.uniform(val[0], val[1])\n",
    "\t\treturn new_hyperparameters\n",
    "\n",
    "\tdef _evaluate_f1_for_hyperparameters(self, hyperparameters, X, y, cv, states_checked):\n",
    "\t\thyperparameters_tuple = tuple(sorted(hyperparameters.items()))\n",
    "\t\tif hyperparameters_tuple in states_checked:\n",
    "\t\t\treturn states_checked[hyperparameters_tuple]\n",
    "\t\telse:\n",
    "\t\t\test = clone(self.estimator)\n",
    "\t\t\test.set_params(**hyperparameters)\n",
    "\t\t\tf1, std = self._evaluate_f1(est, X, y, cv)\n",
    "\t\t\tstates_checked[hyperparameters_tuple] = (f1, std)\n",
    "\t\t\treturn f1, std\n",
    "\n",
    "\tdef _evaluate_f1(self, estimator, X, y, cv):\n",
    "\t\tif self.n_jobs > 1:\n",
    "\t\t\tout = Parallel(n_jobs=self.n_jobs)(\n",
    "\t\t\t\tdelayed(_fit_and_score)(clone(estimator), X, y, self.scoring, train, test, verbose=True,\n",
    "\t\t\t\t                        parameters={}, fit_params={}, return_parameters=False, error_score='raise')\n",
    "\t\t\t\tfor train, test in KFold(cv).split(X)\n",
    "\t\t\t)\n",
    "\t\telse:\n",
    "\t\t\tscores = []\n",
    "\t\t\tfor train, test in KFold(cv).split(X):\n",
    "\t\t\t\testimator.fit(X[train], y[train])\n",
    "\t\t\t\ty_pred = estimator.predict(X[test])\n",
    "\t\t\t\tscores.append(self.scoring(y[test], y_pred))\n",
    "\t\t\tout = (np.mean(scores), np.std(scores))\n",
    "\t\treturn out\n",
    "\n",
    "def crossvalidate_sa(model_name, grid, T=10, T_min=0.001, α=0.9, n_trans=5, max_iter=100, max_runtime=60, cv=5, min_improvement=1e-4, patience=10):\n",
    "\tgrid_mapped = {HYPERPARAMETER_ALIASES.get(k, k): v for k, v in grid.items()}\n",
    "\tmodel_class = MODEL_CLASSES.get(model_name)\n",
    "\tif model_class is None: raise ValueError(f\"Model '{model_name}' is not recognised.\")\n",
    "\tmodel = model_class()\n",
    "\tsa = SA(\n",
    "\t\testimator=model,\n",
    "\t\tgrid=grid_mapped,\n",
    "\t\tscoring=f1_score,\n",
    "\t\tT=T,\n",
    "\t\tT_min=T_min,\n",
    "\t\tα=α,\n",
    "\t\tn_trans=n_trans,\n",
    "\t\tmax_iter=max_iter,\n",
    "\t\tmax_runtime=max_runtime,\n",
    "\t\tcv=cv,\n",
    "\t\tmin_improvement=min_improvement,\n",
    "\t\tpatience=patience\n",
    "\t)\n",
    "\tsa.fit(X_train, y_train)\n",
    "\treturn sa.best_f1_, sa.best_hyperparameters_, sa.grid_f1s_, sa.runtime_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = {\n",
    "\t\"α\": (0.08, 0.1),\n",
    "\t\"τ\": [50, 100],\n",
    "}\n",
    "best_f1, best_hyperparameters, grid_f1s, runtime = crossvalidate_sa(model_name=\"SKLhgb\", grid=grid)\n",
    "print(best_f1)\n",
    "print(best_hyperparameters)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Jupyter",
   "language": "python",
   "name": "jupyter"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
